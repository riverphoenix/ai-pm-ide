{
  "id": "survey-design",
  "name": "Survey Design",
  "category": "discovery",
  "description": "Design effective customer survey questionnaires that yield actionable, unbiased insights",
  "icon": "üìù",
  "example_output": "# Customer Survey: AI PM Tool - Post-Onboarding Experience\n\n## Survey Metadata\n| Attribute | Detail |\n|-----------|--------|\n| **Survey Title** | New User Onboarding Experience Survey |\n| **Target Audience** | Users who completed onboarding in the past 14 days |\n| **Estimated Completion Time** | 6-8 minutes |\n| **Distribution Channel** | In-app prompt + follow-up email |\n| **Sample Size Target** | 150 responses (aim for 20% response rate from 750 eligible users) |\n| **Survey Window** | 14 days open |\n| **Incentive** | 1 month free Pro upgrade |\n\n---\n\n## Research Objectives\n1. Understand how new users perceive the onboarding flow and time-to-first-value\n2. Identify which features drive early activation and which cause confusion\n3. Measure initial satisfaction and likelihood to continue using the product\n4. Discover unmet needs that onboarding did not address\n\n---\n\n## Survey Questions\n\n### Section 1: Background & Context (Screening)\n*Purpose: Ensure respondent fits target profile and segment responses by role/experience.*\n\n**Q1.** What best describes your current role?\n- [ ] Product Manager\n- [ ] Senior Product Manager\n- [ ] Product Lead / Group PM\n- [ ] Director / VP of Product\n- [ ] Product Designer\n- [ ] Other (please specify): ___________\n\n*Type: Single-select with open \"Other\" option*\n\n**Q2.** How many years of product management experience do you have?\n- [ ] Less than 1 year\n- [ ] 1-3 years\n- [ ] 4-7 years\n- [ ] 8+ years\n\n*Type: Single-select*\n\n**Q3.** Before using our tool, how did you typically create PM frameworks and artifacts (e.g., PRDs, RICE analyses, OKRs)?\n- [ ] Manual documents (Google Docs, Word, Notion)\n- [ ] Spreadsheets (Google Sheets, Excel)\n- [ ] General AI tools (ChatGPT, Claude)\n- [ ] Other PM tools (Productboard, Craft.io, etc.)\n- [ ] A combination of the above\n- [ ] I did not regularly create formal PM artifacts\n\n*Type: Single-select*\n\n---\n\n### Section 2: Onboarding Experience\n*Purpose: Evaluate the effectiveness and friction points of the onboarding flow.*\n\n**Q4.** How easy was it to get started with the tool after downloading it?\n\n| 1 | 2 | 3 | 4 | 5 |\n|---|---|---|---|---|\n| Very difficult | Difficult | Neutral | Easy | Very easy |\n\n*Type: 5-point Likert scale*\n\n**Q5.** How long did it take you to generate your first useful output (e.g., a framework, PRD, or analysis)?\n- [ ] Less than 5 minutes\n- [ ] 5-15 minutes\n- [ ] 15-30 minutes\n- [ ] 30-60 minutes\n- [ ] More than 1 hour\n- [ ] I have not generated a useful output yet\n\n*Type: Single-select*\n\n**Q6.** During onboarding, was there a moment where you thought \"this is really valuable\"? If so, what triggered that feeling?\n\n_______________________________________________\n\n*Type: Open-ended text*\n*Analysis note: Code responses for aha-moment themes. Look for patterns around specific frameworks, speed, quality.*\n\n**Q7.** Was there anything during onboarding that confused you or felt unnecessary?\n\n_______________________________________________\n\n*Type: Open-ended text*\n*Analysis note: Code responses for friction categories. Prioritize fixes by frequency.*\n\n---\n\n### Section 3: Feature Value Assessment\n*Purpose: Identify which features drive early value and which are underutilized.*\n\n**Q8.** Which of the following features have you used so far? (Select all that apply)\n- [ ] AI framework generation (RICE, SWOT, JTBD, etc.)\n- [ ] PRD generation\n- [ ] Context document upload\n- [ ] OKR generation\n- [ ] User story generation\n- [ ] Export to Markdown/PDF\n- [ ] Project organization\n- [ ] None of the above\n\n*Type: Multi-select*\n\n**Q9.** Which feature has been most valuable to you so far?\n- [ ] AI framework generation\n- [ ] PRD generation\n- [ ] Context document upload\n- [ ] OKR generation\n- [ ] User story generation\n- [ ] Export functionality\n- [ ] Project organization\n- [ ] I have not found a standout feature yet\n\n*Type: Single-select*\n\n**Q10.** Rate the quality of the AI-generated outputs you have received so far:\n\n| 1 | 2 | 3 | 4 | 5 |\n|---|---|---|---|---|\n| Unusable - required complete rewrite | Poor - required significant editing | Acceptable - required moderate editing | Good - required minor tweaks | Excellent - usable as-is or near as-is |\n\n*Type: 5-point Likert scale*\n\n---\n\n### Section 4: Satisfaction & Future Intent\n*Purpose: Measure overall satisfaction, NPS, and likelihood of continued use.*\n\n**Q11.** How would you rate your overall experience with the tool so far?\n\n| 1 | 2 | 3 | 4 | 5 |\n|---|---|---|---|---|\n| Very dissatisfied | Dissatisfied | Neutral | Satisfied | Very satisfied |\n\n*Type: 5-point Likert scale*\n\n**Q12.** How likely are you to recommend this tool to a fellow product manager?\n\n| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 |\n|---|---|---|---|---|---|---|---|---|---|----|\n| Not at all likely | | | | | | | | | | Extremely likely |\n\n*Type: NPS (0-10 scale)*\n*Analysis note: Calculate NPS score. Segment by role and experience level.*\n\n**Q13.** What is the primary reason for the score you gave above?\n\n_______________________________________________\n\n*Type: Open-ended text (required follow-up to Q12)*\n*Analysis note: This is the most important qualitative question. Code by promoter/passive/detractor themes.*\n\n**Q14.** How likely are you to continue using this tool over the next 30 days?\n- [ ] Definitely will continue\n- [ ] Probably will continue\n- [ ] Not sure\n- [ ] Probably will not continue\n- [ ] Definitely will not continue\n\n*Type: Single-select*\n\n---\n\n### Section 5: Unmet Needs & Open Feedback\n*Purpose: Discover needs the product does not yet address and capture unexpected insights.*\n\n**Q15.** What is the one thing you wish this tool could do that it currently cannot?\n\n_______________________________________________\n\n*Type: Open-ended text*\n*Analysis note: Categorize into feature themes. Cross-reference with roadmap.*\n\n**Q16.** If you could change one thing about the tool to make it more useful, what would it be?\n\n_______________________________________________\n\n*Type: Open-ended text*\n*Analysis note: Distinguish between UX improvements, feature requests, and quality improvements.*\n\n**Q17.** Is there anything else you would like to share about your experience?\n\n_______________________________________________\n\n*Type: Open-ended text (optional)*\n\n---\n\n## Survey Logic & Branching\n\n| Condition | Action |\n|-----------|--------|\n| Q5 = \"I have not generated a useful output yet\" | Skip Q6, show special Q: \"What prevented you from generating your first output?\" |\n| Q14 = \"Probably will not\" or \"Definitely will not\" | Show follow-up: \"What would change your mind?\" |\n| Q1 = \"Other\" | Flag for manual review (may not be target persona) |\n\n---\n\n## Analysis Plan\n\n### Quantitative Metrics\n- **Onboarding ease score**: Mean of Q4 (target: 4.0+)\n- **Time to first value**: Distribution of Q5 (target: 70%+ under 15 minutes)\n- **Output quality score**: Mean of Q10 (target: 3.5+)\n- **CSAT**: Mean of Q11 (target: 4.0+)\n- **NPS**: Calculated from Q12 (target: 40+)\n- **Retention intent**: % \"Definitely/Probably will continue\" in Q14 (target: 75%+)\n\n### Qualitative Coding\n- Q6 (Aha moments): Group by theme, rank by frequency\n- Q7 (Confusion points): Group by theme, prioritize by severity x frequency\n- Q13 (NPS drivers): Separate promoter vs. detractor themes\n- Q15-16 (Feature requests): Categorize and map to roadmap\n\n### Segmentation Cuts\n- By role (PM vs. Senior PM vs. Director)\n- By experience level (junior vs. senior)\n- By previous tool usage (manual vs. AI-assisted)\n\n---\n\n## Survey Best Practices Applied\n- Total questions: 17 (within 15-20 recommended range)\n- Mix of closed (12) and open-ended (5) questions\n- Logical flow: Background, Experience, Features, Satisfaction, Open Feedback\n- No leading or loaded questions\n- NPS with mandatory follow-up for qualitative context\n- Screening question (Q1) to validate respondent fit\n- Estimated completion: 6-8 minutes (under 10-minute threshold for high completion rates)",
  "system_prompt": "You are a survey research methodologist and customer insights expert with expertise in questionnaire design, sampling methodology, and bias reduction.\n\nUsing the provided context, design a professional customer survey that will yield actionable, statistically meaningful, and unbiased insights.\n\n## Structure your survey with these sections:\n\n1. **Survey Metadata Table**: A table with survey title, target audience, estimated completion time, distribution channel, sample size target, survey window duration, and incentive (if any). This gives the team everything needed to launch.\n\n2. **Research Objectives**: 3-5 numbered objectives stating exactly what the survey is designed to learn. Each objective should map to specific questions in the survey.\n\n3. **Survey Questions**: Organized into 4-5 thematic sections. For each section:\n   - State the section purpose in italics\n   - Number questions sequentially across sections (Q1, Q2, ... Q17)\n   - For each question provide: the question text, answer options (for closed questions), question type (single-select, multi-select, Likert scale, NPS, open-ended), and an analysis note in italics explaining how to interpret responses\n   - Use proper markdown formatting for answer options (checkboxes for select questions, tables for scales)\n\n4. **Survey Logic & Branching**: A markdown table defining conditional logic (e.g., if Q5 = X, then skip to Q8 or show follow-up question). Include 2-4 branching rules.\n\n5. **Analysis Plan**: Two subsections:\n   - **Quantitative Metrics**: List each metric to calculate, the source question, and the target benchmark\n   - **Qualitative Coding**: Instructions for coding open-ended responses (themes to look for, how to categorize)\n   - **Segmentation Cuts**: Which respondent attributes to use for cross-tabulation\n\n6. **Survey Best Practices Applied**: A brief summary confirming the survey follows research methodology best practices (question count, completion time, question mix, bias avoidance, logical flow).\n\n## Guidelines:\n- Keep total questions between 12-20. More than 20 causes drop-off.\n- Target 5-8 minute completion time. Never exceed 10 minutes.\n- Start with easy, non-threatening questions (demographics/screening) before asking for opinions.\n- Mix question types: include single-select, multi-select, Likert scales, NPS, and open-ended.\n- Always follow a quantitative rating question (like NPS) with an open-ended \"why\" question.\n- Avoid leading questions, double-barreled questions, and loaded language.\n- Use 5-point Likert scales consistently (not mixing 5-point and 7-point).\n- Include at least 2-3 open-ended questions to capture unexpected insights.\n- End with a catch-all open feedback question.\n- Provide explicit analysis instructions so the team knows exactly what to do with the data.",
  "guiding_questions": [
    "What is the primary research question you want this survey to answer?",
    "Who is the target audience for this survey (role, segment, behavior-based cohort)?",
    "What specific decisions will be informed by the survey results?",
    "Are there specific features, experiences, or topics you want to ask about?",
    "How will you distribute the survey (in-app, email, social, intercept)?",
    "What is your target sample size and expected response rate?",
    "Are there any hypotheses you want to validate or invalidate with this survey?"
  ],
  "supports_visuals": false
}