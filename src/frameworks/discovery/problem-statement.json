{
  "id": "problem-statement",
  "name": "Problem Statement",
  "category": "discovery",
  "description": "Define and frame the core problem clearly to align teams and guide solution development",
  "icon": "‚ùì",
  "example_output": "# Problem Statement: PM Artifact Creation Bottleneck\n\n## Problem Statement (Concise)\n**Product managers at B2B SaaS companies waste 15-20 hours per week manually creating strategic artifacts (PRDs, frameworks, prioritization analyses) using disconnected tools, resulting in inconsistent quality, delayed decision-making, and reduced time for high-value activities like customer discovery and strategic thinking.**\n\n---\n\n## Problem Framing\n\n### Who is affected?\n- **Primary**: Product managers at B2B SaaS companies (Series A through public), typically managing 1-3 products with cross-functional squads of 5-12 people.\n- **Secondary**: Product leadership (Directors, VPs) who rely on PM artifacts for roadmap reviews, board presentations, and strategic planning.\n- **Tertiary**: Engineering, Design, and Sales teams who consume PM artifacts (PRDs, user stories, competitive analyses) to do their own work effectively.\n\n### What is the problem?\nProduct managers are expected to produce a growing volume of strategic and tactical artifacts -- PRDs, prioritization frameworks (RICE, ICE, WSJF), competitive analyses, user personas, OKRs, stakeholder updates, and more. Today, this work is done manually using a fragmented set of tools (Google Docs, spreadsheets, Confluence, Notion, Miro) with no PM-specific intelligence or automation.\n\nThe result is threefold:\n1. **Time drain**: PMs spend 40-60% of their working hours on artifact creation rather than strategic work.\n2. **Quality inconsistency**: The same PM produces varying quality outputs depending on time pressure, energy, and familiarity with a given framework.\n3. **Knowledge loss**: Context, research, and strategic rationale are scattered across tools and rarely carried forward from one artifact to the next.\n\n### When and where does it occur?\n- **Planning cycles**: Most acute during quarterly planning (OKRs, roadmap reviews) when artifact volume spikes 3-4x.\n- **Cross-functional handoffs**: When PMs hand off PRDs to engineering or present prioritization to leadership.\n- **New PM onboarding**: When a PM joins a team and must learn existing frameworks, conventions, and product context simultaneously.\n- **Tool boundaries**: Every time a PM switches between tools (Notion to Sheets to Figma to Jira), context is lost and reformatting is required.\n\n### Why does it matter?\n- **Business impact**: Slower time-to-decision means slower time-to-market. Companies with faster planning cycles ship 2x more features per quarter (Pendo 2024 State of PM Report).\n- **Talent impact**: PM burnout is rising. 62% of PMs report feeling overwhelmed by artifact creation demands (ProductPlan 2024 Survey). Top PM talent leaves for companies with better tooling.\n- **Quality impact**: Inconsistent frameworks lead to poor prioritization, misaligned teams, and wasted engineering effort. A single mis-prioritized quarter can cost $500K-$2M in engineering time.\n\n---\n\n## 5 Whys Analysis\n\n| Level | Question | Answer |\n|-------|----------|--------|\n| **Why 1** | Why do PMs spend 15-20 hours/week on artifacts? | Because each artifact is created from scratch using generic tools not designed for PM workflows. |\n| **Why 2** | Why are they using generic tools? | Because no purpose-built PM tool offers AI-powered framework generation with product-specific context. |\n| **Why 3** | Why does product context matter? | Because frameworks without context produce generic outputs that require extensive manual editing and customization. |\n| **Why 4** | Why is manual editing so time-consuming? | Because PMs must re-inject domain knowledge, customer insights, and strategic context that generic tools cannot retain. |\n| **Why 5** | Why can't existing tools retain this context? | Because current tools treat each document as an isolated artifact with no shared knowledge layer across the PM workflow. |\n\n**Root Cause**: The fundamental issue is the absence of a persistent, product-aware context layer that connects PM frameworks, research, and strategic artifacts into a coherent workflow.\n\n---\n\n## Problem Boundaries\n\n### In Scope\n- Artifact creation workflow for individual PMs (PRDs, frameworks, analyses, OKRs)\n- Context management across multiple documents and projects\n- AI-assisted generation of PM-specific frameworks\n- Quality consistency of strategic outputs\n\n### Out of Scope\n- Team collaboration and multi-user editing (future phase)\n- Integration with project management tools (Jira, Linear)\n- PM career development and coaching\n- Replacing PM judgment and decision-making\n\n### Constraints\n- Must work offline / local-first (data privacy is non-negotiable for PMs handling confidential roadmaps)\n- Must produce outputs that look hand-crafted (stakeholders distrust visibly AI-generated content)\n- Must support existing export formats (Markdown, Google Docs, PDF)\n- Must not require more than 5 minutes of onboarding to generate first useful output\n\n---\n\n## Impact Assessment\n\n| Dimension | Current State | Desired State | Gap |\n|-----------|--------------|---------------|-----|\n| Time on artifacts | 15-20 hrs/week | 5-8 hrs/week | 10-12 hrs saved |\n| Framework quality consistency | Varies 40-90% quality | Consistent 80%+ quality | Baseline quality floor |\n| Context carried across artifacts | 0% (start from scratch) | 80%+ (persistent context) | Full context layer |\n| Time to first usable draft | 45-90 minutes | 3-5 minutes | 90%+ reduction |\n| Tools required | 5-7 tools | 1 primary tool | 4-6 tools eliminated |\n\n---\n\n## How Might We...\nUsing the problem framing above, here are key opportunity areas:\n\n1. **HMW** reduce artifact creation time from hours to minutes while maintaining stakeholder-ready quality?\n2. **HMW** build a persistent context layer that makes every new artifact smarter than the last?\n3. **HMW** help PMs apply the right framework for their specific situation rather than defaulting to what they already know?\n4. **HMW** ensure AI-generated outputs feel authentic and personalized rather than generic and templated?\n5. **HMW** make the onboarding experience so fast that PMs see value before they finish their first coffee?\n\n---\n\n## Validation Criteria\nWe will know we have correctly identified and solved this problem when:\n- [ ] PMs report spending less than 8 hours/week on artifact creation (measured via time-tracking survey)\n- [ ] Framework output quality scores 4+ out of 5 from stakeholder review (blind comparison test)\n- [ ] 70%+ of generated outputs are shared with stakeholders with minimal editing (< 10 minutes of edits)\n- [ ] NPS from PM users exceeds 50 within first 90 days\n- [ ] Week-2 retention rate exceeds 60% (users return after first week)",
  "system_prompt": "You are a product strategy expert specializing in problem definition and framing, drawing on principles from Design Thinking, the Toyota Production System (5 Whys), and the Jobs to Be Done framework.\n\nUsing the provided context, create a rigorous problem statement that precisely defines the problem, its scope, its impact, and the opportunity it represents.\n\n## Structure your problem statement with these sections:\n\n1. **Problem Statement (Concise)**: A single bold paragraph (2-3 sentences max) that captures WHO is affected, WHAT the problem is, WHY it matters, and WHAT the consequences are. This should be quotable in any meeting or document.\n\n2. **Problem Framing**: Expand on four dimensions:\n   - **Who is affected?** Primary, secondary, and tertiary stakeholders. Be specific about segments, roles, company profiles.\n   - **What is the problem?** Detailed description with 2-3 concrete manifestations of the problem.\n   - **When and where does it occur?** Specific contexts, triggers, and environments where the problem is most acute.\n   - **Why does it matter?** Business impact, user impact, and market impact. Use numbers and data where possible.\n\n3. **5 Whys Analysis**: A markdown table drilling from the surface symptom to the root cause. Each \"Why\" should peel back a layer. The final row should reveal a fundamental, non-obvious root cause. Summarize the root cause in a bold statement below the table.\n\n4. **Problem Boundaries**:\n   - **In Scope**: What is included in this problem definition (4-5 bullets)\n   - **Out of Scope**: What is explicitly excluded (3-4 bullets)\n   - **Constraints**: Non-negotiable limitations that any solution must respect (3-4 bullets)\n\n5. **Impact Assessment**: A markdown table with columns: Dimension, Current State, Desired State, Gap. Include 4-5 measurable dimensions.\n\n6. **How Might We...**: 4-5 \"How Might We\" opportunity statements derived from the problem framing. Each should be broad enough to inspire multiple solutions but specific enough to be actionable.\n\n7. **Validation Criteria**: 4-5 checkboxes defining how the team will know the problem has been correctly identified and solved. Each criterion should be measurable.\n\n## Guidelines:\n- Resist the urge to jump to solutions. This document is about the problem, not the answer.\n- Use data, research, and evidence wherever possible. If citing statistics, note the source.\n- The concise problem statement should pass the \"hallway test\" -- if you read it to a random colleague, they should immediately understand the problem.\n- Distinguish between symptoms and root causes. The 5 Whys should make this distinction clear.\n- The How Might We statements should energize the team, not constrain them.\n- Be honest about what is out of scope. Scope creep starts with ambiguous problem definitions.",
  "guiding_questions": [
    "Who is the primary user or customer experiencing this problem?",
    "What is the specific pain point or unmet need you are trying to address?",
    "How frequently does this problem occur and in what context or situation?",
    "What is the measurable impact of this problem (time lost, revenue, satisfaction)?",
    "What existing solutions or workarounds do users currently rely on?",
    "What constraints must any solution respect (technical, budget, regulatory)?",
    "How will you know the problem has been solved? What does success look like?"
  ],
  "supports_visuals": false
}