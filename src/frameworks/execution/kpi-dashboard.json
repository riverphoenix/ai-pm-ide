{
  "id": "kpi-dashboard",
  "name": "KPI Dashboard Design",
  "category": "execution",
  "description": "Design a structured KPI dashboard with metrics hierarchy, owners, and thresholds",
  "icon": "ðŸ“Š",
  "example_output": "# KPI Dashboard: AI PM Workspace\n\n## Dashboard Overview\n**Product**: AI-powered Product Management Workspace\n**Reporting Period**: Q1 2026 (January - March)\n**Dashboard Owner**: Head of Product\n**Update Cadence**: Weekly (every Monday by 10am)\n**Data Sources**: Mixpanel (product analytics), Stripe (revenue), Intercom (support), PostgreSQL (internal)\n\n---\n\n## Tier 1: Executive KPIs (Board-Level)\n\nThese are the top-line metrics reviewed by leadership weekly and reported to the board monthly.\n\n| KPI | Definition | Current | Target | Trend | Status |\n|---|---|---|---|---|---|\n| Monthly Recurring Revenue (MRR) | Total recurring subscription revenue | $42,500 | $75,000 | +18% MoM | On Track |\n| Monthly Active Users (MAU) | Unique users with 1+ session in 30 days | 3,200 | 6,000 | +22% MoM | On Track |\n| Net Revenue Retention (NRR) | Revenue retained from existing cohort including expansion | 108% | 115% | +2pp MoM | At Risk |\n| Customer Acquisition Cost (CAC) | Total S&M spend / new customers acquired | $128 | <$100 | -8% MoM | At Risk |\n| NPS Score | Quarterly Net Promoter Score survey | 47 | 55 | +5 pts QoQ | On Track |\n\n### Tier 1 Alert Thresholds\n- **Red**: MRR growth <10% MoM, NRR <100%, CAC >$150\n- **Yellow**: MRR growth 10-15% MoM, NRR 100-110%, CAC $100-$150\n- **Green**: MRR growth >15% MoM, NRR >110%, CAC <$100\n\n---\n\n## Tier 2: Product & Growth KPIs (Team-Level)\n\nThese metrics are owned by specific teams and reviewed in weekly team standups.\n\n### Acquisition Metrics\n| KPI | Owner | Current | Target | Status |\n|---|---|---|---|---|\n| Website-to-Signup conversion | Growth | 4.2% | 6.0% | At Risk |\n| Signup-to-Activation rate | Growth | 38% | 55% | At Risk |\n| Organic traffic (monthly) | Marketing | 28,000 | 50,000 | On Track |\n| Paid channel ROAS | Marketing | 2.8x | 3.5x | On Track |\n\n### Engagement Metrics\n| KPI | Owner | Current | Target | Status |\n|---|---|---|---|---|\n| Weekly Frameworks Generated / User | Product | 1.2 | 3.5 | At Risk |\n| DAU/MAU Ratio | Product | 32% | 45% | On Track |\n| Avg. session duration | Product | 8.4 min | 12 min | On Track |\n| Feature adoption (context upload) | Product | 24% | 50% | At Risk |\n\n### Retention Metrics\n| KPI | Owner | Current | Target | Status |\n|---|---|---|---|---|\n| Day 1 Retention | Growth | 62% | 75% | On Track |\n| Day 7 Retention | Growth | 34% | 50% | At Risk |\n| Day 30 Retention | Growth | 18% | 30% | At Risk |\n| Churn Rate (monthly) | CS | 6.8% | <4% | At Risk |\n\n### Revenue Metrics\n| KPI | Owner | Current | Target | Status |\n|---|---|---|---|---|\n| Free-to-Paid conversion | Growth | 3.8% | 7% | At Risk |\n| Average Revenue Per User (ARPU) | Product | $18.50 | $25 | On Track |\n| Expansion Revenue (% of total) | Sales | 12% | 20% | On Track |\n| Payback Period (months) | Finance | 7.2 | <6 | At Risk |\n\n---\n\n## Tier 3: Operational KPIs (Functional Teams)\n\n### Engineering\n| KPI | Current | Target |\n|---|---|---|\n| Deployment frequency | 8/week | 12/week |\n| Mean time to recovery (MTTR) | 2.1 hrs | <1 hr |\n| API uptime | 99.91% | 99.95% |\n| P95 API latency | 420ms | <300ms |\n\n### AI/ML\n| KPI | Current | Target |\n|---|---|---|\n| Framework output quality (user rating) | 3.6/5 | 4.3/5 |\n| Generation success rate | 94.2% | 99% |\n| Avg. LLM cost per generation | $0.06 | <$0.05 |\n| Prompt iteration cycle time | 3 days | 1 day |\n\n### Customer Support\n| KPI | Current | Target |\n|---|---|---|\n| First response time | 4.2 hrs | <2 hrs |\n| Resolution time | 18 hrs | <12 hrs |\n| CSAT (support interactions) | 4.1/5 | 4.5/5 |\n| Ticket volume per 100 users | 8.3 | <5 |\n\n---\n\n## Dashboard Layout Specification\n\n### Row 1: Executive Summary Strip\n- 5 cards showing Tier 1 KPIs with sparkline trends and RAG status indicators\n- Time range toggle: Week / Month / Quarter\n\n### Row 2: Funnel Visualization\n- Full acquisition funnel: Traffic > Signup > Activation > Retention > Revenue\n- Conversion rates between each stage with week-over-week deltas\n\n### Row 3: Engagement & Retention Charts\n- Left: DAU/WAU/MAU trend line (12-week view)\n- Center: Retention cohort heatmap (weekly cohorts, 8-week window)\n- Right: Feature adoption bar chart (top 10 features)\n\n### Row 4: Revenue & Unit Economics\n- Left: MRR waterfall chart (new, expansion, contraction, churn)\n- Right: CAC/LTV trend with payback period overlay\n\n---\n\n## Review Cadence & Escalation\n\n| Cadence | Audience | Metrics Reviewed | Action |\n|---|---|---|---|\n| Daily | Engineering | Uptime, latency, error rates | Immediate fix if threshold breached |\n| Weekly | Product & Growth | Tier 2 metrics, experiment results | Adjust sprint priorities |\n| Bi-weekly | Leadership | Tier 1 + Tier 2 summary | Strategic decisions, resource allocation |\n| Monthly | Board | Tier 1 KPIs + narrative | Investor update, fundraising signals |\n| Quarterly | All Hands | Full dashboard + OKR progress | Company-wide alignment |",
  "system_prompt": "You are a product analytics and business intelligence expert specializing in KPI dashboard design for product-led companies.\n\nYour task is to help the user design a structured, actionable KPI dashboard that gives their team clear visibility into product and business health.\n\n## Methodology:\n\nFollow a tiered KPI hierarchy approach:\n\n1. **Tier 1 - Executive KPIs (3-5 metrics)**: Board-level metrics that represent overall business health. These are lagging indicators like MRR, MAU, NRR, CAC, and NPS. Include alert thresholds (Red/Yellow/Green) for each.\n\n2. **Tier 2 - Product & Growth KPIs (12-20 metrics)**: Team-level metrics organized into four categories:\n   - **Acquisition**: How users find and sign up for the product\n   - **Engagement**: How actively users interact with core features\n   - **Retention**: How well the product keeps users over time\n   - **Revenue**: How effectively the product monetizes\n   Each metric must have a clear owner, current baseline, target, and RAG status.\n\n3. **Tier 3 - Operational KPIs (8-15 metrics)**: Functional team metrics for engineering, support, AI/ML, or other relevant teams. These are the internal health indicators.\n\n4. **Dashboard Layout**: Specify the visual layout with rows, chart types, and interactive elements. Be prescriptive about what goes where.\n\n5. **Review Cadence**: Define who reviews what metrics, how often, and what actions are triggered by different threshold breaches.\n\n## Structure the Output As:\n- Dashboard Overview (product, period, owner, cadence, data sources)\n- Tier 1: Executive KPIs table with thresholds\n- Tier 2: Product & Growth KPIs organized by category\n- Tier 3: Operational KPIs by function\n- Dashboard Layout Specification\n- Review Cadence & Escalation matrix\n\n## Best Practices:\n- Every metric must have an owner; unowned metrics are useless\n- Include current baseline AND target; a metric without a target is just a number\n- Use RAG (Red/Amber/Green) status for quick scanning\n- Organize metrics in a funnel or AARRR framework where applicable\n- Limit Tier 1 to 5 metrics maximum; executives should see the signal, not the noise\n- Include both leading indicators (predictive) and lagging indicators (outcome)\n- Specify data sources to ensure dashboards are buildable\n- Define alert thresholds explicitly so teams know when to escalate\n- Use markdown tables for clean, structured output",
  "guiding_questions": [
    "What is your product and what stage is it at (pre-launch, growth, scale, mature)?",
    "Who is the primary audience for this dashboard (executives, product team, investors)?",
    "What are your 3-5 most important business outcomes right now?",
    "What tools do you use for analytics and data (e.g., Mixpanel, Amplitude, Looker, Google Analytics)?",
    "What metrics do you currently track, and which ones feel most useful vs. missing?",
    "How is your team structured â€” which functions need their own operational metrics?",
    "What is your current review cadence for metrics, and what would you like it to be?"
  ],
  "supports_visuals": false
}
