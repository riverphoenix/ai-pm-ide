{
  "id": "moscow",
  "name": "MoSCoW Prioritization",
  "category": "prioritization",
  "description": "Categorize features into Must, Should, Could, and Won't buckets for release planning",
  "icon": "ðŸŽ¯",
  "example_output": "# MoSCoW Prioritization Analysis\n\n## Context\n**Product**: PM IDE - AI-Powered Product Management Tool\n**Release**: v2.0 (Q3 2026)\n**Team Capacity**: 4 engineers, 1 designer, 12-week cycle\n**Stakeholder Input**: Product leadership, engineering leads, customer advisory board\n\n---\n\n## Must Have (Non-Negotiable)\nThese are critical requirements. Without them, the release has no viable value and should not ship.\n\n### 1. Framework Template Engine\n- **Description**: Core engine that loads and executes framework JSON definitions, rendering structured outputs from user inputs.\n- **Justification**: This is the foundational capability of the product. Without it, no frameworks can be executed. Every other feature depends on this.\n- **Risk if excluded**: Product is non-functional. Launch is impossible.\n- **Acceptance Criteria**: Engine loads all framework JSON files, processes guiding questions, generates structured markdown output.\n\n### 2. User Authentication & Session Management\n- **Description**: Secure login, session persistence, and user-scoped data storage.\n- **Justification**: Users must be able to save their work and return to it. Data isolation between users is a legal and trust requirement.\n- **Risk if excluded**: No ability to save or retrieve analyses. Unacceptable for any SaaS product.\n- **Acceptance Criteria**: OAuth 2.0 login, session tokens with 24h expiry, encrypted storage per user.\n\n### 3. Export to Markdown/PDF\n- **Description**: Allow users to export any completed framework analysis as a formatted Markdown or PDF document.\n- **Justification**: Users need to share outputs with stakeholders who do not use the tool. This was the #1 requested feature in beta feedback.\n- **Risk if excluded**: Users cannot extract value from the tool into their existing workflows.\n- **Acceptance Criteria**: One-click export producing clean, well-formatted documents with all tables and scores intact.\n\n---\n\n## Should Have (Important but not critical)\nThese features add significant value and are expected by users, but the product can launch without them if necessary.\n\n### 4. AI-Powered Scoring Suggestions\n- **Description**: When a user fills in a framework, the AI suggests scores or categorizations based on the context provided.\n- **Justification**: Reduces cognitive load and provides a starting point. Differentiates from static templates. Strong alignment with our AI-first positioning.\n- **Impact if deferred**: Product still works but feels more manual. Competitive differentiation weakens.\n- **Estimated Effort**: 3 engineer-weeks\n\n### 5. Collaboration & Sharing\n- **Description**: Share a framework analysis with teammates via link, with optional comment threads.\n- **Justification**: Product decisions are collaborative. Enabling shared views reduces the need to export and email. High demand from beta users.\n- **Impact if deferred**: Users rely on export + email workflow. Functional but friction-heavy.\n- **Estimated Effort**: 4 engineer-weeks\n\n---\n\n## Could Have (Nice to have)\nThese are desirable features that enhance the experience but have limited impact on core value delivery.\n\n### 6. Custom Framework Builder\n- **Description**: Allow power users to create their own framework JSON definitions via a visual editor.\n- **Justification**: Extends the product beyond built-in frameworks. Appeals to advanced users and consultants.\n- **Impact if deferred**: Users are limited to pre-built frameworks. Acceptable for v2.0 as the built-in library is already extensive.\n- **Estimated Effort**: 5 engineer-weeks\n\n### 7. Dashboard with Historical Analyses\n- **Description**: A dashboard view showing all past analyses with search, filter, and trend comparisons.\n- **Justification**: Useful for tracking how priorities evolve over time. Adds a layer of strategic insight.\n- **Impact if deferred**: Users manage past analyses manually. Minor inconvenience.\n- **Estimated Effort**: 3 engineer-weeks\n\n---\n\n## Won't Have (This Release)\nThese features are explicitly out of scope for this release. They may be revisited in future cycles.\n\n### 8. Third-Party Integrations (Jira, Linear, Notion)\n- **Description**: Push prioritized items directly into project management tools.\n- **Rationale for exclusion**: Integration work is high-effort and requires partnership agreements. The export feature covers the immediate need. Planned for v3.0.\n\n### 9. Multi-Language Support\n- **Description**: Localized UI and framework outputs in non-English languages.\n- **Rationale for exclusion**: Current user base is 95% English-speaking. Internationalization is a significant engineering investment better suited for a dedicated cycle.\n\n### 10. Mobile App\n- **Description**: Native iOS/Android application.\n- **Rationale for exclusion**: Usage data shows 98% desktop access. Mobile adds complexity with minimal user value at this stage.\n\n---\n\n## Summary Table\n\n| # | Feature | Category | Effort | Dependency |\n|---|---------|----------|--------|------------|\n| 1 | Framework Template Engine | Must | 6 wks | None |\n| 2 | Auth & Sessions | Must | 3 wks | None |\n| 3 | Export to Markdown/PDF | Must | 2 wks | #1 |\n| 4 | AI Scoring Suggestions | Should | 3 wks | #1 |\n| 5 | Collaboration & Sharing | Should | 4 wks | #2 |\n| 6 | Custom Framework Builder | Could | 5 wks | #1 |\n| 7 | Historical Dashboard | Could | 3 wks | #2 |\n| 8 | Third-Party Integrations | Won't | - | - |\n| 9 | Multi-Language Support | Won't | - | - |\n| 10 | Mobile App | Won't | - | - |\n\n## Capacity Check\n- **Must Have total**: ~11 engineer-weeks (fits within 12-week cycle with buffer)\n- **Should Have total**: ~7 engineer-weeks (can fit if Musts complete on schedule)\n- **Could Have total**: ~8 engineer-weeks (defer to next cycle unless ahead of schedule)\n\n## Recommendation\nCommit to all 3 Must Have items as the release baseline. Plan for Should Have items as stretch goals with clear go/no-go checkpoints at week 8. Explicitly communicate Won't Have items to stakeholders to manage expectations and prevent scope creep.",
  "system_prompt": "You are a product prioritization expert specializing in the MoSCoW method. Your task is to help product managers categorize features and requirements into four distinct priority buckets: Must Have, Should Have, Could Have, and Won't Have.\n\nFollow these principles when categorizing:\n\n**Must Have (Mo)**: Requirements that are non-negotiable for the release. Without these, the product or release is not viable. Apply the \"minimum usable subset\" test: if removing this feature makes the product broken or unusable for its core purpose, it is a Must. Be rigorous here - teams often over-classify items as Must Have. Challenge each item by asking: \"Will the release truly fail without this?\"\n\n**Should Have (S)**: Important requirements that add significant value but are not critical for launch. These are features where workarounds exist, even if painful. If time runs short, these can be deferred to the next release without catastrophic consequences. Quantify the impact of deferral where possible.\n\n**Could Have (Co)**: Desirable features that have a smaller impact on user satisfaction or business outcomes. These are included only if time and resources permit. They often represent polish, convenience, or nice-to-have enhancements. Be honest about the incremental value these provide.\n\n**Won't Have (W)**: Features explicitly excluded from this release. This is NOT a rejection - it is a conscious scope decision. Clearly state the rationale for exclusion and indicate whether the item is planned for a future release or requires further validation.\n\nFor your analysis, structure the output as follows:\n1. Begin with a context section stating the product, release, team capacity, and key stakeholders consulted.\n2. For each category, list features with: description, justification for the categorization, risk or impact assessment, and acceptance criteria (for Must Have) or estimated effort (for Should/Could).\n3. Create a summary table showing all features, their category, effort estimate, and dependencies.\n4. Perform a capacity check: sum the effort for Must Have items and verify they fit within the stated capacity. Then assess whether Should Have items can fit as stretch goals.\n5. End with a clear recommendation on what to commit to, what to plan as stretch, and what to communicate to stakeholders as out of scope.\n\nUse markdown formatting with headers, tables, bold text, and horizontal rules for clear visual separation. Be specific and opinionated - vague categorizations are not helpful. When the user has not provided enough context, make reasonable assumptions and state them explicitly.",
  "guiding_questions": [
    "What features or requirements are you trying to prioritize?",
    "What is the scope of this release (timeline, team size, capacity)?",
    "Are there any hard deadlines or external commitments driving this release?",
    "Who are the key stakeholders and what are their top priorities?",
    "Are there any technical dependencies or sequencing constraints between features?",
    "What does 'minimum viable' look like for this release?",
    "Have any features already been promised or committed to customers?"
  ],
  "supports_visuals": false
}
