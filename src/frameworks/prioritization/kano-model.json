{
  "id": "kano-model",
  "name": "Kano Model",
  "category": "prioritization",
  "description": "Categorize features by customer satisfaction impact using Kano's five quality types",
  "icon": "ðŸ“Š",
  "example_output": "# Kano Model Analysis\n\n## Context\n**Product**: PM IDE - AI-Powered Product Management Tool\n**Target Segment**: Product managers at mid-size SaaS companies (50-500 employees)\n**Data Source**: Customer interviews (n=24), support tickets (last 90 days), NPS verbatims\n**Analysis Date**: Q2 2026\n\n---\n\n## Feature Classification\n\n### Basic Needs (Must-Be Quality)\nThese are expected by default. Their presence does not increase satisfaction, but their absence causes strong dissatisfaction. Customers rarely mention these explicitly - they assume they exist.\n\n| Feature | Evidence | Satisfaction if Absent | Priority |\n|---------|----------|----------------------|----------|\n| Save & persist analyses | 100% of users expect this. No one praised it; 3 users reported data loss bugs and gave NPS 2-3. | Severe dissatisfaction | Critical - fix immediately |\n| Framework outputs render correctly | Users expect formatted tables, headers, and scores to display without errors. | High dissatisfaction | Critical |\n| Sub-second response for UI interactions | Page loads and navigation must feel instant. 4 users complained about \"sluggish\" sidebar. | Moderate dissatisfaction | High |\n\n**Strategic Implication**: Invest in reliability and performance before adding new features. These are table stakes. Under-investing here erodes trust regardless of how many exciting features you ship.\n\n---\n\n### Performance Needs (One-Dimensional Quality)\nSatisfaction scales linearly with the degree of fulfillment. More is better. These are the features customers actively compare across competing products.\n\n| Feature | Customer Signal | Current State | Improvement Opportunity |\n|---------|----------------|---------------|------------------------|\n| Number of built-in frameworks | \"I wish you had [X] framework\" appeared in 8 of 24 interviews. Users compare framework count across tools. | 9 frameworks | Adding 5-10 more frameworks would directly increase perceived value. Each additional framework is incremental satisfaction. |\n| AI output quality & accuracy | Users rate helpfulness of AI suggestions. Higher quality = higher satisfaction, linearly. | Mixed reviews - \"sometimes great, sometimes generic\" | Invest in prompt engineering and context-awareness. Every quality improvement is felt by users. |\n| Export format options | Users want Markdown, PDF, Notion, Confluence. Each additional format removes a friction point. | Markdown only | Add PDF as next priority. Each new format adds measurable satisfaction. |\n| Speed of AI generation | Users timed the generation. Faster = more satisfied. No diminishing returns observed up to current speeds. | 4-8 seconds avg | Reducing to under 3 seconds would meaningfully improve experience. |\n\n**Strategic Implication**: These are your competitive levers. Invest proportionally - each increment of improvement delivers proportional satisfaction gains. Benchmark against competitors on these dimensions.\n\n---\n\n### Excitement Needs (Attractive Quality)\nThese delight customers when present but cause no dissatisfaction when absent. Customers do not expect these - they are surprise-and-delight features that drive word-of-mouth and loyalty.\n\n| Feature | Delight Potential | Feasibility | Strategic Value |\n|---------|------------------|-------------|----------------|\n| AI auto-suggests which framework to use | When a user describes their problem, the AI recommends the best framework. 6 users said \"wow, that would be amazing\" in interviews. | Medium - requires intent classification model | High - differentiator. No competitor does this. |\n| Compare analyses over time | Show how your RICE scores or MoSCoW categories changed quarter-over-quarter. \"I never thought of that but I love it\" - User 14. | Medium - requires versioned storage | High - creates long-term engagement loop. |\n| One-click stakeholder presentation | Generate a polished slide deck from any analysis. Unexpected but highly valued when demonstrated in prototype testing. | High effort - slide generation is complex | Medium - impressive demo, but high build cost. |\n| Smart conflict detection | AI flags when two frameworks give contradictory recommendations and explains why. | Low effort - comparison logic on existing outputs | High - builds trust in the tool's intelligence. |\n\n**Strategic Implication**: Pick 1-2 excitement features per release to create buzz and differentiation. These are what make users recommend your product. Do not over-invest - their absence is not penalized.\n\n---\n\n### Indifferent Qualities\nFeatures that neither increase nor decrease satisfaction regardless of presence. Avoid investing here.\n\n| Feature | Evidence |\n|---------|----------|\n| Customizable color themes | Asked about in interviews. 22 of 24 users said \"I don't care\" or \"default is fine.\" |\n| Detailed API documentation | Only 1 of 24 users expressed interest. Not relevant for the target segment. |\n| Gamification (badges, streaks) | Tested in concept. Unanimous indifference from PM audience. \"I'm not here to play games.\" |\n\n**Strategic Implication**: Do not build these. Redirect any planned effort to Performance or Excitement features.\n\n---\n\n### Reverse Qualities\nFeatures that actively decrease satisfaction for some users when present.\n\n| Feature | Evidence | Risk |\n|---------|----------|------|\n| Mandatory onboarding tutorial | 5 users found it patronizing. \"I'm a PM, I know what a RICE score is.\" | Moderate - makes first experience worse for power users |\n| Auto-sharing analyses with team by default | Privacy concern raised by 3 users. \"I don't want my draft thinking shared automatically.\" | High - trust violation |\n\n**Strategic Implication**: Either remove these or make them opt-in with sensible defaults. Never force reverse-quality features on users.\n\n---\n\n## Kano Classification Summary\n\n| Feature | Category | Investment Priority |\n|---------|----------|--------------------|\n| Save & persist analyses | Basic | Fix/maintain |\n| Correct rendering | Basic | Fix/maintain |\n| Fast UI response | Basic | Fix/maintain |\n| More frameworks | Performance | High |\n| AI output quality | Performance | High |\n| Export formats | Performance | Medium |\n| AI generation speed | Performance | Medium |\n| Auto-suggest framework | Excitement | High |\n| Compare over time | Excitement | Medium |\n| Stakeholder presentation | Excitement | Low |\n| Smart conflict detection | Excitement | High |\n| Color themes | Indifferent | None |\n| API docs | Indifferent | None |\n| Gamification | Indifferent | None |\n| Mandatory onboarding | Reverse | Remove/redesign |\n| Auto-sharing | Reverse | Remove/redesign |\n\n## Recommended Investment Allocation\n- **40%** on Basic needs (reliability, performance, bug fixes)\n- **35%** on Performance needs (framework count, AI quality, exports)\n- **20%** on Excitement needs (1-2 delighters per cycle)\n- **5%** on validating and removing Reverse qualities\n- **0%** on Indifferent features\n\n## Key Insight\nThe biggest risk is neglecting Basic needs while chasing Excitement features. Ensure your foundation is solid before investing in delight. The biggest opportunity is \"Auto-suggest framework\" - it is technically feasible, highly differentiating, and directly aligned with the product's AI-first positioning.",
  "system_prompt": "You are a product strategist specializing in the Kano Model of customer satisfaction. Your task is to classify product features into Kano's five quality categories and provide actionable investment recommendations.\n\nApply these category definitions precisely:\n\n**Basic Needs (Must-Be)**: Features customers expect by default. Their presence does not increase satisfaction, but their absence causes severe dissatisfaction. These are often unspoken expectations. Test: ask \"How would you feel if this feature were missing?\" - if the answer is strong dissatisfaction, it is Basic.\n\n**Performance Needs (One-Dimensional)**: Features where satisfaction correlates linearly with the degree of fulfillment. More is better, less is worse. These are the features customers actively evaluate when comparing products. Test: both presence and absence affect satisfaction proportionally.\n\n**Excitement Needs (Attractive)**: Features that delight when present but cause no dissatisfaction when absent. Customers do not expect these - they are surprises. These drive word-of-mouth, loyalty, and differentiation. Test: customers say \"I never thought of that but I love it.\"\n\n**Indifferent Qualities**: Features that have no impact on satisfaction whether present or absent. Investing here is waste. Be honest about identifying these - teams often mistake their own enthusiasm for customer interest.\n\n**Reverse Qualities**: Features that actively decrease satisfaction for some customer segments when present. These are often well-intentioned features that backfire. Identify these early to avoid negative impact.\n\nStructure your analysis as follows:\n1. State the product context, target segment, and data sources used for classification.\n2. For each category, present features in a table with evidence, satisfaction impact, and priority.\n3. Include a strategic implication note after each category explaining what the classification means for investment decisions.\n4. Provide a summary classification table of all features.\n5. Recommend a percentage-based investment allocation across categories.\n6. End with a key insight highlighting the single most important finding.\n\nWhen classifying features, cite specific evidence (customer quotes, usage data, support ticket patterns, interview findings). If no data is provided, make reasonable assumptions and state them clearly. Be opinionated - the value of Kano analysis is in making clear distinctions, not hedging.\n\nUse markdown with tables, bold text, horizontal rules, and headers for visual clarity. Always remind the user that Kano categories are dynamic - today's Excitement feature becomes tomorrow's Basic need as markets mature.",
  "guiding_questions": [
    "What product and target customer segment are you analyzing?",
    "What features or capabilities are you trying to classify?",
    "Do you have customer research data (interviews, surveys, NPS feedback, support tickets)?",
    "What do customers explicitly complain about when things go wrong?",
    "What features do competitors offer that your customers expect as standard?",
    "Have you tested any concepts or prototypes that generated unexpected delight?",
    "Are there any features you suspect customers are indifferent to?"
  ],
  "supports_visuals": false
}
